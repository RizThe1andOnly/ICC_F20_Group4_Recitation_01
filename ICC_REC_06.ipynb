{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 32-bit",
   "display_name": "Python 3.8.5 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "6d58817d7a36abfa3a827e4c983e24a2b2aeec7ad475bf8b9406aeab7b3302d2"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"task6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE_PATH = \"Rec1_F19_Files_to_zip/file01_Hd_Sp_Freq\""
   ]
  },
  {
   "source": [
    "# MapReduce Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Procedure:\n",
    "\n",
    "#### The problem will be broken down into three phases which are explained below:\n",
    "\n",
    "Given document will be broken down line by line with spark. <br>\n",
    "There will be two identical RDDs created from the document.<br>\n",
    "The two RDDs will be used to determine line numbers. One RDD (RDD_REF) <br>\n",
    "will simply be turned into a list, with each element being a line<br>\n",
    "this way the index will correspond to line number. The other line<br>\n",
    "will be mapped to its line index using RDD_REF (see mapLineWithIndex() function below). <br>\n",
    "Now we have lines with their corresponding line number which will allow us to rebuild<br>\n",
    "the document as it was and without duplicates.\n",
    "\n",
    "The next phase is to split each line's words and get rid of duplicates. flatMap will <br>\n",
    "be used to get every word in the document with both their line number and position<br>\n",
    "in that line. After which duplicates will be removed using series of group and map<br>\n",
    "operations (see RDD operation chain and respective functions). Only non-duplicates will<br>\n",
    "be present in the RDD now, each with their line and position within the line.\n",
    "\n",
    "All the words will be grouped and sorted by line index. All words,positionInLine pairs<br>\n",
    "will be grouped in their respective lines. A final reducer will create a single string<br>\n",
    "that represents the recreated document without any duplicates, where each word will <br>\n",
    "retain its original position in the line."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['hello', 'world', 'bye', 'how', 'are', 'you', 'what', 'is', 'your', 'name', '', '\\n', 'i', 'study', 'spark', 'and', 'also', 'hadoop', '\\n', 'prefer', 'to', '\\n', 'but', 'have', 'spend', 'more', 'hours', 'studying', '\\n', 'difficult', 'compile', 'debug', 'some', 'say', '\\n', 'am', 'interested', 'in', 'marreduce', 'which', 'part', 'of', '\\n', 'so', 'shall', 'choose', '\\n', 'perhaps', 'can', 'compromise', \"let's\", 'forget', 'about', 'it', 'all', 'do', 'sql', '\\n', 'cloud', 'computing', '\\n', 'supposed', 'get', 'familiar', 'with', 'nosql', 'pighive', '\\n', 'much', '\\n', 'oh', 'it.', \"i'll\", 'only', 'as', 'this', 'started', '\\n', 'no,', \"don't\", 'want', 'be', 'modern?', 'then', \"i'd\", 'better']\n"
     ]
    }
   ],
   "source": [
    "r\"\"\"\n",
    "\n",
    "Code Organization:\n",
    "\n",
    "    Section_1 : Create RDDs and create lines list\n",
    "    Section_2 : Define Functions to be used by RDD operations like map\n",
    "    Section_3 : RDD function chain to obtain ouptut\n",
    "    Section_4 : Process output to be printed to a file\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Section_1:\n",
    "lines = sc.textFile(INPUT_FILE_PATH)\n",
    "linesRef = sc.textFile(INPUT_FILE_PATH)\n",
    "linesRef = linesRef.collect()\n",
    "\n",
    "\n",
    "# Section_2: Most Functions contain documentation explaining their tasks\n",
    "def getRidOfDupes(termTuple):\n",
    "    r\"\"\"\n",
    "        Gets rid of duplicate words while retaining the first occurrence.\n",
    "    \n",
    "    @param:\n",
    "        termTuple: contains the word and the line and inLine index\n",
    "            - [0] : word\n",
    "            - [1] : list((line,inLine))\n",
    "\n",
    "    @return:\n",
    "        tuple with word and indicies of is first occurrence\n",
    "            - [0] : word\n",
    "            - [1] : (line,inLine)\n",
    "\n",
    "    @Procedure:\n",
    "        Go through list of (line,inLine) for the given word and then keep the\n",
    "        tuples that have the lowest \"line\" value. After that keep only the\n",
    "        element with the lowest \"inLine\" value. Then return the word with\n",
    "        firstLine and firstInLinePosition.\n",
    "\n",
    "    \"\"\"\n",
    "    key = termTuple[0]\n",
    "    occurrences =  list(map(lambda x: (x[0],x[1]),termTuple[1])) # copy over the termTuple list to local list; couldn't process otherwise\n",
    "    termIndices = []\n",
    "\n",
    "    #get all of the line values for each word into a single list to get the minimum value\n",
    "    for i in occurrences:\n",
    "        termIndices.append(i[0])\n",
    "    firstLineOccurrence = min(termIndices)\n",
    "    \n",
    "    #get all of the inLine values belonging to the minimum line into one list to get minimum\n",
    "    inLineOccurrences = []\n",
    "    for j in occurrences:\n",
    "        if j[0] == firstLineOccurrence :\n",
    "            inLineOccurrences.append(j[1])\n",
    "    firstInLineOccurrence = min(inLineOccurrences)\n",
    "\n",
    "    return key,(firstLineOccurrence,firstInLineOccurrence)\n",
    "\n",
    "\n",
    "def mapLineWithLineIndex(line):\n",
    "    r\"\"\"\n",
    "        Get Index for each line.\n",
    "\n",
    "    @param:\n",
    "        line : line from document\n",
    "\n",
    "    @return:\n",
    "        tuple : (line,lineIndex)\n",
    "\n",
    "    @Procedure:\n",
    "        Give each line its index, position in the document.\n",
    "        This is done by using an already existing list with\n",
    "        each line, the index of that list serving as the \n",
    "        line index. The input line is checked against each\n",
    "        line in the list and if there is a match then that\n",
    "        index is used for the input line.\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(len(linesRef)):\n",
    "        if line == linesRef[i]:\n",
    "            return (line,i)\n",
    "\n",
    "def splitLineWithLineIndex(line):\n",
    "    r\"\"\"\n",
    "        \"line\" here is a tuple with two elements.\n",
    "        line[0] = the actual line\n",
    "        line[1] = index of the line\n",
    "    \"\"\"\n",
    "    tokenized = line[0].split(\" \")\n",
    "    outputList = []\n",
    "    for i in range(len(tokenized)):\n",
    "        token = tokenized[i]\n",
    "        outputList.append((token.lower(),(line[1],i)))\n",
    "    return outputList\n",
    "\n",
    "def reAlignByLines(token):\n",
    "    r\"\"\"\n",
    "    @param:\n",
    "        token:\n",
    "            - [0] : word\n",
    "            - [1] : tuple with line and inLine position\n",
    "                -[0] : line index\n",
    "                -[1] : in linke index\n",
    "    @return:\n",
    "        tuple: (line,(word,positionInLine))\n",
    "    \"\"\"\n",
    "    word = token[0]\n",
    "    line = token[1][0]\n",
    "    postitionInLine = token[1][1]\n",
    "    return line,(word,postitionInLine)\n",
    "\n",
    "def mergeLineContent(line):\n",
    "    r\"\"\"\n",
    "        Combines everyword for a single line into a single list\n",
    "\n",
    "    @param:\n",
    "        \"line\" here is the following:\n",
    "            - line[0] = the line number\n",
    "            - line[1] = iterator that has elements: tuple(word,positionInLine)\n",
    "                - in the following function x[0] = word and x[1]= positionInLine\n",
    "    @return:\n",
    "        tuple: (lineNumber,listOfSortedList)\n",
    "    \"\"\"\n",
    "    lineNum = line[0]\n",
    "    wordList = list(map(lambda x: (x[0],x[1]),line[1]))\n",
    "    wordList.sort(key=lambda x: x[1])\n",
    "    sortedWordList = list(map(lambda kvPair: kvPair[0],wordList))\n",
    "    return lineNum,sortedWordList\n",
    "\n",
    "def reduceToSolution(acc,current):\n",
    "    r\"\"\"\n",
    "        Reduces RDD to single string that has answer.\n",
    "    \"\"\"\n",
    "    stringList_acc = acc[1]\n",
    "    stringList_acc.append('\\n')\n",
    "    stringList_current = current[1]\n",
    "    for i in stringList_current:\n",
    "        stringList_acc.append(i)\n",
    "    return acc\n",
    "\n",
    "\n",
    "# Section_3 :\n",
    "r\"\"\"\n",
    "    Each line has a separate RDD operation to process data.\n",
    "    Some of these functions are passed a predefined function\n",
    "    as input instead of lambda. The RDD operations and their\n",
    "    purpose are as follows:\n",
    "\n",
    "        -map        -> Uses: mapLineWithLineIndex, map line to its index (position in document) -> (line,lineIndex)\n",
    " \n",
    "        -flatMap    -> Uses: splitLineWithLineIndex, tokenizes each line and creates a list of words with the line index and position in line -> list(word,(lineIndex,                       position))\n",
    "        \n",
    "        -groupByKey -> Groups by word, so we can detect duplicates -> word,list((lineIndex,positionInLine))\n",
    "        \n",
    "        -map        -> Uses: getRidOfDupes(), Gets rid of duplicate words while retaining the 1st occurrence -> word,(lineIndex,positionInLine) (1st occurrence for                          line and inLine)\n",
    "        \n",
    "        -map        -> Uses: reAlignByLines(), Change key value to make line the key -> (lineIndex,(word,positionInLine))\n",
    "        \n",
    "        -groupByKey -> Groups all word to their respective line -> (lineIndex,list((word,positionInLine),...))\n",
    "        \n",
    "        -sortByKey  -> Sorts the lines by index so lines that appear first will be first in RDD\n",
    "        \n",
    "        -map        -> Uses: mergeLineContent(), Merges all words that belong to each line retaining the order of the words in the line-> (lineIndex,list                                    (wordsInOrder))\n",
    "        \n",
    "        -reduce     -> Uses: reduceToSolution(), Combines all lines and the words within each line; a '\\n' placed between each line so when printed to txt doc there                         will be a line break -> String\n",
    "\"\"\"\n",
    "noDupes = lines.map(lambda line: mapLineWithLineIndex(line))\\\n",
    "                .flatMap(splitLineWithLineIndex)\\\n",
    "                .groupByKey()\\\n",
    "                .map(getRidOfDupes)\\\n",
    "                .map(reAlignByLines)\\\n",
    "                .groupByKey()\\\n",
    "                .sortByKey()\\\n",
    "                .map(mergeLineContent)\\\n",
    "                .reduce(reduceToSolution)\n",
    "\n",
    "# Section_4 : \n",
    "noDupesRdd = sc.parallelize(noDupes[1])\n",
    "noDupesRdd.saveAsTextFile(\"Problem06_NoDuplicates_Output\")\n",
    "print(noDupesRdd.collect())"
   ]
  },
  {
   "source": [
    "# Output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hello world bye how are you what is your name  \n i study spark and also hadoop \n prefer to \n but have spend more hours studying \n difficult compile debug some say \n am interested in marreduce which part of \n so shall choose \n perhaps can compromise let's forget about it all do sql \n cloud computing \n supposed get familiar with nosql pighive \n much \n oh it. i'll only as this started \n no, don't want be modern? then i'd better \n"
     ]
    }
   ],
   "source": [
    "#format the output to match the input format:\n",
    "outptuString = \"\"\n",
    "for token in noDupesRdd.collect():\n",
    "    outptuString += token + \" \"\n",
    "print(outptuString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ]
}